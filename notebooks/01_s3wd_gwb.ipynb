{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db9d230",
   "metadata": {},
   "source": [
    "# 00 · S3WD Baseline（中文）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995b9506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【可视化字体】已设置为宋体优先（若系统缺失则自动回退）。\n",
      "【Python】 3.11.5\n",
      "【Pandas/Numpy】 2.0.3 1.26.4\n",
      "【模块路径】\n",
      "  zh_utils   -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\zh_utils.py\n",
      "  data_io    -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\data_io.py\n",
      "  features   -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\features.py\n",
      "  gwb        -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\gwb.py\n",
      "  objective  -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\objective.py\n",
      "  trainer    -> e:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\trainer.py\n",
      "【函数签名】load_table_auto: (path: 'str', label_col: 'Optional[str | int]' = None, positive_label=1, continuous_label: 'Optional[str]' = None, threshold: 'Optional[float]' = None, threshold_op: 'str' = '>=') -> 'Tuple[pd.DataFrame, pd.Series]'\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 0. 环境初始化与模块导入（中文）\n",
    "# ================================\n",
    "import os, sys, platform, importlib, inspect, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (f1_score, balanced_accuracy_score, precision_score, recall_score,\n",
    "                             matthews_corrcoef, cohen_kappa_score, roc_auc_score)\n",
    "# 1) 确保项目根目录在 sys.path[0]（notebooks/ 的上一级）\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "# 2) 导入自研库（s3wdlib）各模块，并强制重载确保拿到最新版实现\n",
    "import s3wdlib.zh_utils as zh_utils\n",
    "import s3wdlib.data_io as data_io\n",
    "import s3wdlib.features as features\n",
    "import s3wdlib.gwb as gwb\n",
    "import s3wdlib.objective as objective\n",
    "import s3wdlib.trainer as trainer\n",
    "\n",
    "importlib.reload(zh_utils)\n",
    "importlib.reload(data_io)\n",
    "importlib.reload(features)\n",
    "importlib.reload(gwb)\n",
    "importlib.reload(objective)\n",
    "importlib.reload(trainer)\n",
    "\n",
    "# 3) 把常用符号直接引入（可读性更好）\n",
    "from s3wdlib.zh_utils import set_chinese_font, fix_minus\n",
    "from s3wdlib.data_io import load_table_auto, minmax_scale_fit_transform\n",
    "from s3wdlib.features import rank_features_mi, make_levels\n",
    "from s3wdlib.gwb import GWBProbEstimator\n",
    "from s3wdlib.objective import S3WDParams\n",
    "from s3wdlib.trainer import PSOParams, pso_learn_thresholds\n",
    "from s3wdlib.config_loader import load_yaml_cfg, extract_vars, show_cfg\n",
    "\n",
    "# 4) 可视化中文设置（宋体优先，负号正常）\n",
    "set_chinese_font(); fix_minus()\n",
    "print(\"【可视化字体】已设置为宋体优先（若系统缺失则自动回退）。\")\n",
    "\n",
    "# 5) 版本与路径自检（定位是否导入了正确文件）\n",
    "print(\"【Python】\", platform.python_version())\n",
    "print(\"【Pandas/Numpy】\", pd.__version__, np.__version__)\n",
    "print(\"【模块路径】\")\n",
    "print(\"  zh_utils   ->\", zh_utils.__file__)\n",
    "print(\"  data_io    ->\", data_io.__file__)\n",
    "print(\"  features   ->\", features.__file__)\n",
    "print(\"  gwb        ->\", gwb.__file__)\n",
    "print(\"  objective  ->\", objective.__file__)\n",
    "print(\"  trainer    ->\", trainer.__file__)\n",
    "print(\"【函数签名】load_table_auto:\", inspect.signature(data_io.load_table_auto))\n",
    "\n",
    "# 6) 随机种子（方便复现；如需完全一致可统一设置）\n",
    "np.random.seed(42)\n",
    "\n",
    "# 7) 警告精简（可选）\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cdf5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【配置快照】\n",
      "- DATA: {'data_dir': '../data', 'data_file': 'airlines_train_regression_1000000.arff', 'continuous_label': 'DepDelay', 'threshold': 15, 'threshold_op': '>', 'label_col': None, 'positive_label': None, 'test_size': 0.3, 'val_size': 0.3, 'random_state': 42}\n",
      "- LEVEL: {'level_pcts': [0.6, 0.8, 1.0], 'ranker': 'mi'}\n",
      "- KWB: {'k': 6, 'metric': 'euclidean', 'eps': 1e-06}\n",
      "- GWB: {'k': 6, 'metric': 'euclidean', 'eps': 1e-06, 'mode': 'epanechnikov', 'bandwidth': 0.8, 'bandwidth_scale': 1.0, 'use_faiss': True, 'faiss_gpu': True}\n",
      "- S3WD: {'c1': 0.37, 'c2': 0.63, 'xi_min': 0.1, 'theta_pos': 0.9, 'theta_neg': 0.1, 'sigma': 3.0, 'regret_mode': 'utility', 'penalty_large': 1000000.0, 'gamma_last': True, 'gap': 0.02}\n",
      "- PSO: {'particles': 20, 'iters': 20, 'w_max': 0.9, 'w_min': 0.4, 'c1': 2.8, 'c2': 1.3, 'seed': 42}\n",
      "【参数就绪（来自 YAML）】 {'DATA_PATH': '../data\\\\airlines_train_regression_1000000.arff', 'label': 'DepDelay>15', 'splits': 'test=0.3, val=0.3, seed=42', 'gwb': {'k': 6, 'mode': 'epanechnikov', 'bandwidth': 0.8, 'use_faiss': True, 'faiss_gpu': True}, 'pso': {'particles': 20, 'iters': 20}}\n"
     ]
    }
   ],
   "source": [
    "# === 配置接入（YAML → dataclass → 变量字典）===\n",
    "# wine\n",
    "# CFG = load_yaml_cfg(\"../configs/s3wd_wine.yaml\")  # ← 如换配置文件，只改这里\n",
    "# Heart\n",
    "# CFG = load_yaml_cfg(\"../configs/s3wd_heart.yaml\")\n",
    "# Credit\n",
    "# CFG = load_yaml_cfg(\"../configs/s3wd_credit.yaml\")\n",
    "# airline\n",
    "CFG = load_yaml_cfg(\"../configs/s3wd_airline.yaml\")\n",
    "\n",
    "\n",
    "\n",
    "V   = extract_vars(CFG)\n",
    "show_cfg(CFG)\n",
    "\n",
    "# ✅ 兼容“连续列二值化”和“已有二值标签”两种配置\n",
    "if \"CONT_LABEL\" in V:\n",
    "    label_desc = f\"{V['CONT_LABEL']}{V['CONT_OP']}{V['CONT_THRESH']}\"\n",
    "elif \"LABEL_COL\" in V:\n",
    "    label_desc = f\"{V['LABEL_COL']}=={V.get('POSITIVE_LABEL', 1)}\"\n",
    "else:\n",
    "    label_desc = \"(未检测到标签配置)\"\n",
    "\n",
    "gwb_desc = {\n",
    "    \"k\": V[\"GWB_K\"],\n",
    "    \"mode\": V.get(\"GWB_mode\"),\n",
    "    \"bandwidth\": V.get(\"GWB_bandwidth\"),\n",
    "    \"use_faiss\": bool(V.get(\"GWB_use_faiss\", False)),\n",
    "    \"faiss_gpu\": bool(V.get(\"GWB_faiss_gpu\", False)),\n",
    "}\n",
    "print(\"【参数就绪（来自 YAML）】\", {\n",
    "    \"DATA_PATH\": V[\"DATA_PATH\"],\n",
    "    \"label\": label_desc,\n",
    "    \"splits\": f\"test={V['TEST_SIZE']}, val={V['VAL_SIZE']}, seed={V['SEED']}\",\n",
    "    \"gwb\": gwb_desc,\n",
    "    \"pso\": {\"particles\": V[\"PSO_particles\"], \"iters\": V[\"PSO_iters\"]}\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41be3dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【标签策略】连续列二值化：DepDelay > 15\n",
      "【数据加载完毕】样本数=1000000，特征数=9，正类比例=0.1559\n",
      "【数据加载】X_all, y_all = (1000000, 9) (1000000,)\n",
      "【数据切分】Xtr/Xte = (700000, 9) (300000, 9)\n"
     ]
    }
   ],
   "source": [
    "# === 读取数据（兼容“连续列二值化 / 已有二值标签”两种配置）+ 切分 ===\n",
    "from s3wdlib.data_io import load_table_auto\n",
    "\n",
    "# 统一参数打包（不存在的键用 .get() 不报错）\n",
    "kw = dict(\n",
    "    path=V[\"DATA_PATH\"],\n",
    "    label_col=V.get(\"LABEL_COL\"),\n",
    "    positive_label=V.get(\"POSITIVE_LABEL\"),\n",
    "    continuous_label=V.get(\"CONT_LABEL\"),\n",
    "    threshold=V.get(\"CONT_THRESH\"),\n",
    "    threshold_op=V.get(\"CONT_OP\"),\n",
    ")\n",
    "\n",
    "# 友好提示\n",
    "if V.get(\"CONT_LABEL\") is not None:\n",
    "    print(f\"【标签策略】连续列二值化：{V['CONT_LABEL']} {V['CONT_OP']} {V['CONT_THRESH']}\")\n",
    "elif V.get(\"LABEL_COL\") is not None:\n",
    "    print(f\"【标签策略】已有标签列：{V['LABEL_COL']} == {V.get('POSITIVE_LABEL', 1)} 视为正类\")\n",
    "else:\n",
    "    raise RuntimeError(\"未检测到标签配置（既无 CONT_* 也无 LABEL_COL）。请检查 YAML。\")\n",
    "\n",
    "# 读取数据\n",
    "X_all, y_all = load_table_auto(**kw)\n",
    "print(\"【数据加载】X_all, y_all =\", X_all.shape, y_all.shape)\n",
    "\n",
    "# 切分（与 YAML 一致）\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=V[\"TEST_SIZE\"],\n",
    "    random_state=V[\"SEED\"],\n",
    "    stratify=y_all\n",
    ")\n",
    "print(\"【数据切分】Xtr/Xte =\", Xtr.shape, Xte.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9229e4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【归一化】已对训练/测试集进行 MinMax 缩放到 [0,1]。\n",
      "【分层复核】总特征=9 | L1=5 L2=7 L3=9\n"
     ]
    }
   ],
   "source": [
    "# 1) 训练集内切出验证集（仅用于阈值寻优）\n",
    "Xtr_sub, Xva, ytr_sub, yva = train_test_split(\n",
    "    Xtr, ytr, test_size=V[\"VAL_SIZE\"], stratify=ytr, random_state=V[\"SEED\"]\n",
    ")\n",
    "\n",
    "# 2) 归一化（仅在训练子集拟合）\n",
    "Xtr2, Xva2, scaler = minmax_scale_fit_transform(Xtr_sub, Xva)\n",
    "Xte2 = pd.DataFrame(scaler.transform(Xte), columns=Xte.columns)\n",
    "\n",
    "# 3) 分层（训练子集上）\n",
    "feat_rank, mi_vals = rank_features_mi(Xtr2, ytr_sub)\n",
    "L1, L2, L3 = make_levels(feat_rank)\n",
    "print(f\"【分层复核】总特征={len(feat_rank)} | L1={len(L1)} L2={len(L2)} L3={len(L3)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22732d74",
   "metadata": {},
   "source": [
    "## GWB（Algorithm 1）训练与三层概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "878a9ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【GWB 完成】验证/测试三层概率就绪。\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gwb_kwargs = {\n",
    "    \"k\": int(V[\"GWB_K\"]),\n",
    "    \"mode\": V.get(\"GWB_mode\", \"epanechnikov\"),\n",
    "    \"bandwidth\": V.get(\"GWB_bandwidth\"),\n",
    "    \"bandwidth_scale\": V.get(\"GWB_bandwidth_scale\", 1.0),\n",
    "    \"use_faiss\": bool(V.get(\"GWB_use_faiss\", False)),\n",
    "    \"faiss_gpu\": bool(V.get(\"GWB_faiss_gpu\", False)),\n",
    "}\n",
    "gwb_kwargs = {k: v for k, v in gwb_kwargs.items() if v is not None}\n",
    "gwb1 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L1], ytr_sub)\n",
    "gwb2 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L2], ytr_sub)\n",
    "gwb3 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L3], ytr_sub)\n",
    "p1_va = gwb1.predict_proba(Xva2[L1]); p2_va = gwb2.predict_proba(Xva2[L2]); p3_va = gwb3.predict_proba(Xva2[L3])\n",
    "p1_te = gwb1.predict_proba(Xte2[L1]); p2_te = gwb2.predict_proba(Xte2[L2]); p3_te = gwb3.predict_proba(Xte2[L3])\n",
    "print(\"【GWB 完成】验证/测试三层概率就绪。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8e4f8",
   "metadata": {},
   "source": [
    "## 验证集 PSO 学阈值（信息增益−后悔值 + 单调序 + ξ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e73fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【PSO 学到阈值（验证集）】 ['α1=0.5830/β1=0.1651', 'α2=0.5830/β2=0.1651', 'α3=0.5830/β3=0.2920'] γ3=0.5000\n",
      "【适应度/约束】 {'fit': -0.0079, 'pen_bnd': 0.0, 'pen_mono': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# 5) 验证集 PSO 学阈值（信息增益−后悔值 + 单调序 + ξ）\n",
    "s3 = S3WDParams(\n",
    "    c1=V[\"S3_c1\"], c2=V[\"S3_c2\"], xi_min=V[\"S3_xi_min\"],\n",
    "    theta_pos=V[\"S3_theta_pos\"], theta_neg=V[\"S3_theta_neg\"],\n",
    "    penalty_large=V[\"S3_penalty_large\"],\n",
    "    gamma_last=V.get(\"S3_gamma_last\"),   # ← 用 gamma_last（True 或 0.5）\n",
    "    gap=V.get(\"S3_gap\", 0.02)\n",
    ")\n",
    "pso = PSOParams(\n",
    "    particles=V[\"PSO_particles\"], iters=V[\"PSO_iters\"],\n",
    "    w_max=V[\"PSO_w_max\"], w_min=V[\"PSO_w_min\"],\n",
    "    c1=V[\"PSO_c1\"], c2=V[\"PSO_c2\"], seed=V[\"PSO_seed\"]\n",
    ")\n",
    "(best_th, best_fit, detail) = pso_learn_thresholds([p1_va, p2_va, p3_va], yva.values, s3, pso)\n",
    "\n",
    "alphas, betas, gamma3 = best_th\n",
    "print(\"【PSO 学到阈值（验证集）】\", [f\"α{i+1}={a:.4f}/β{i+1}={b:.4f}\" for i,(a,b) in enumerate(zip(alphas,betas))], f\"γ3={gamma3:.4f}\")\n",
    "print(\"【适应度/约束】\", {\"fit\":round(best_fit,4), \"pen_bnd\":detail.get(\"pen_bnd\",None), \"pen_mono\":detail.get(\"pen_mono\",None)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769b5df6",
   "metadata": {},
   "source": [
    "## 测试集序贯三支决策 + 评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53342cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【样本流转（学到的阈值）】L1 POS/BND/NEG = 4835 173292 121873  | L2 POS/BND/NEG = 3371 112752 57169  | L3 POS/NEG = 7808 104944\n",
      "【评估（测试集）】 {'F1': 0.1406, 'BAC': 0.5243, 'Prec': 0.2756, 'Rec': 0.0944, 'MCC': 0.0784, 'Kappa': 0.0664, 'AUC': 0.5243}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6) 测试集序贯三支决策 + 评估\n",
    "def _seq_predict_eval(p1, p2, p3, y_true, a1, b1, a2, b2, g3):\n",
    "    POS1 = (p1 >= a1); NEG1 = (p1 <= b1); BND1 = (~POS1) & (~NEG1)\n",
    "    p2s = p2[BND1]; POS2 = np.zeros_like(BND1, bool); NEG2 = np.zeros_like(BND1, bool)\n",
    "    POS2[BND1] = (p2s >= a2); NEG2[BND1] = (p2s <= b2)\n",
    "    BND2 = BND1 & (~POS2) & (~NEG2)\n",
    "    p3s = p3[BND2]; POS3 = np.zeros_like(BND2, bool); NEG3 = np.zeros_like(BND2, bool)\n",
    "    POS3[BND2] = (p3s >= g3); NEG3[BND2] = ~POS3[BND2]\n",
    "    y_hat = np.full_like(y_true, -1, int)\n",
    "    y_hat[POS1]=1; y_hat[NEG1]=0; y_hat[POS2]=1; y_hat[NEG2]=0; y_hat[POS3]=1; y_hat[NEG3]=0\n",
    "    flow = {\"L1\":(int(POS1.sum()), int(BND1.sum()), int(NEG1.sum())),\n",
    "            \"L2\":(int(POS2.sum()), int(BND2.sum()), int(NEG2.sum())),\n",
    "            \"L3\":(int(POS3.sum()), int(NEG3.sum()))}\n",
    "    return y_hat, flow\n",
    "\n",
    "a1,b1 = float(alphas[0]), float(betas[0])\n",
    "a2,b2 = float(alphas[1]), float(betas[1])\n",
    "g3    = float(gamma3)\n",
    "\n",
    "y_hat, flow = _seq_predict_eval(p1_te, p2_te, p3_te, yte.values,\n",
    "                           float(alphas[0]), float(betas[0]),\n",
    "                           float(alphas[1]), float(betas[1]),\n",
    "                           g3=0.5)\n",
    "print(\"【样本流转（学到的阈值）】L1 POS/BND/NEG =\", *flow[\"L1\"], \" | L2 POS/BND/NEG =\", *flow[\"L2\"], \" | L3 POS/NEG =\", *flow[\"L3\"])\n",
    "\n",
    "mask = (y_hat >= 0)\n",
    "metrics = {\n",
    "    'F1': round(f1_score(yte[mask], y_hat[mask]),4),\n",
    "    'BAC': round(balanced_accuracy_score(yte[mask], y_hat[mask]),4),\n",
    "    'Prec': round(precision_score(yte[mask], y_hat[mask]),4),\n",
    "    'Rec': round(recall_score(yte[mask], y_hat[mask]),4),\n",
    "    'MCC': round(matthews_corrcoef(yte[mask], y_hat[mask]),4),\n",
    "    'Kappa': round(cohen_kappa_score(yte[mask], y_hat[mask]),4),\n",
    "    'AUC': round(roc_auc_score(yte[mask], y_hat[mask]),4)\n",
    "}\n",
    "print(\"【评估（测试集）】\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad80fd",
   "metadata": {},
   "source": [
    "## 10 次独立 70/30 划分（Train→Val(寻优)→Test(评估)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d3fafc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【数据加载完毕】样本数=1000000，特征数=9，正类比例=0.1559\n",
      "【归一化】已对训练/测试集进行 MinMax 缩放到 [0,1]。\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33936\\1849759564.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m# —— 跑 10 次 —— #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[0mbase_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PSO_seed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_one_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_seed\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     rows.append({\n\u001b[0;32m    121\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;34m'L1_POS'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'L1_BND'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'L1_NEG'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'L1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33936\\1849759564.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(seed)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mgwb_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgwb_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mgwb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGWBProbEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgwb_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mgwb2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGWBProbEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgwb_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mgwb3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGWBProbEstimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgwb_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtr2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mp1_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXva2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mp2_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXva2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mp3_va\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXva2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mp1_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mp2_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mp3_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgwb3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXte2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mL3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# === 验证集上 PSO 学阈值 ===\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     s3 = S3WDParams(\n",
      "\u001b[1;32me:\\yan\\组\\三支决策\\机器学习\\C三支决策与不平衡数据集分类\\S3WD实验\\s3wdlib\\gwb.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_faiss_runtime\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_faiss_index\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FAISS 索引未正确初始化。\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mdistances2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_faiss_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_k_effective\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistances2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\faiss\\class_wrappers.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[0mI\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswig_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\Lib\\site-packages\\faiss\\swigfaiss.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, n, x, k, distances, labels, params)\u001b[0m\n\u001b[0;32m  11782\u001b[0m         r\"\"\"\n\u001b[0;32m  11783\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mresident\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCPU\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11784\u001b[0m         \u001b[0mGPU\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mcopies\u001b[0m \u001b[0mare\u001b[0m \u001b[0mperformed\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mneeded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11785\u001b[0m         \"\"\"\n\u001b[1;32m> 11786\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_swigfaiss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGpuIndex_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# === 外层评测：10 次独立 70/30 划分（Train→Val(寻优)→Test(评估)）===\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.metrics import (f1_score, balanced_accuracy_score, precision_score, recall_score,\n",
    "                             matthews_corrcoef, cohen_kappa_score, roc_auc_score)\n",
    "import numpy as np, pandas as pd, importlib\n",
    "\n",
    "# 确保拿到最新版目标/训练器实现\n",
    "import s3wdlib.objective as objective, s3wdlib.trainer as trainer\n",
    "importlib.reload(objective); importlib.reload(trainer)\n",
    "from s3wdlib.objective import S3WDParams\n",
    "from s3wdlib.trainer import PSOParams, pso_learn_thresholds\n",
    "from s3wdlib.data_io import minmax_scale_fit_transform, load_table_auto\n",
    "from s3wdlib.features import rank_features_mi, make_levels\n",
    "from s3wdlib.gwb import GWBProbEstimator\n",
    "\n",
    "def _seq_predict(p1, p2, p3, y_true, a1, b1, a2, b2, g3):\n",
    "    POS1 = (p1 >= a1); NEG1 = (p1 <= b1); BND1 = (~POS1) & (~NEG1)\n",
    "    p2s = p2[BND1]; POS2 = np.zeros_like(BND1, bool); NEG2 = np.zeros_like(BND1, bool)\n",
    "    POS2[BND1] = (p2s >= a2); NEG2[BND1] = (p2s <= b2)\n",
    "    BND2 = BND1 & (~POS2) & (~NEG2)\n",
    "    p3s = p3[BND2]; POS3 = np.zeros_like(BND2, bool); NEG3 = np.zeros_like(BND2, bool)\n",
    "    POS3[BND2] = (p3s >= g3); NEG3[BND2] = ~POS3[BND2]\n",
    "    y_hat = np.full_like(y_true, -1, int)\n",
    "    y_hat[POS1]=1; y_hat[NEG1]=0; y_hat[POS2]=1; y_hat[NEG2]=0; y_hat[POS3]=1; y_hat[NEG3]=0\n",
    "    flow = {\"L1\":(int(POS1.sum()), int(BND1.sum()), int(NEG1.sum())),\n",
    "            \"L2\":(int(POS2.sum()), int(BND2.sum()), int(NEG2.sum())),\n",
    "            \"L3\":(int(POS3.sum()), int(NEG3.sum()))}\n",
    "    return y_hat, flow\n",
    "\n",
    "def _safe_auc(y_true, y_pred):\n",
    "    try:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "def run_one_split(seed: int):\n",
    "    # === 读取全量数据（兼容 “连续列二值化 / 已有标签列”）===\n",
    "    kw = dict(\n",
    "        path=V[\"DATA_PATH\"],\n",
    "        label_col=V.get(\"LABEL_COL\"),\n",
    "        positive_label=V.get(\"POSITIVE_LABEL\"),\n",
    "        continuous_label=V.get(\"CONT_LABEL\"),\n",
    "        threshold=V.get(\"CONT_THRESH\"),\n",
    "        threshold_op=V.get(\"CONT_OP\"),\n",
    "    )\n",
    "    X_all, y_all = load_table_auto(**kw)\n",
    "\n",
    "    # === 外层一次 70/30 划分 ===\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=V[\"TEST_SIZE\"], random_state=seed)\n",
    "    (tr_idx, te_idx), = sss.split(X_all, y_all)\n",
    "    Xtr_all, Xte = X_all.iloc[tr_idx], X_all.iloc[te_idx]\n",
    "    ytr_all, yte  = y_all.iloc[tr_idx], y_all.iloc[te_idx]\n",
    "\n",
    "    # === 训练集再切 val（仅用于阈值寻优）===\n",
    "    Xtr, Xva, ytr, yva = train_test_split(\n",
    "        Xtr_all, ytr_all, test_size=V[\"VAL_SIZE\"], stratify=ytr_all, random_state=seed\n",
    "    )\n",
    "\n",
    "    # === 归一化仅在训练子集拟合 ===\n",
    "    Xtr2, Xva2, scaler = minmax_scale_fit_transform(Xtr, Xva)\n",
    "    Xte2 = pd.DataFrame(scaler.transform(Xte), columns=Xte.columns)\n",
    "\n",
    "    # === 分层在训练子集上确定（互信息）===\n",
    "    feat_rank, mi_vals = rank_features_mi(Xtr2, ytr)   # ← 修正 ytr_sub 未定义\n",
    "    L1, L2, L3 = make_levels(feat_rank, V.get(\"LEVEL_PCTS\", [0.6,0.8,1.0]))\n",
    "\n",
    "    # === GWB 训练（训练子集）与概率（val/test）===\n",
    "    gwb_kwargs = {\n",
    "        \"k\": int(V[\"GWB_K\"]),\n",
    "        \"mode\": V.get(\"GWB_mode\", \"epanechnikov\"),\n",
    "        \"bandwidth\": V.get(\"GWB_bandwidth\"),\n",
    "        \"bandwidth_scale\": V.get(\"GWB_bandwidth_scale\", 1.0),\n",
    "        \"use_faiss\": bool(V.get(\"GWB_use_faiss\", False)),\n",
    "        \"faiss_gpu\": bool(V.get(\"GWB_faiss_gpu\", False)),\n",
    "    }\n",
    "    gwb_kwargs = {k: v for k, v in gwb_kwargs.items() if v is not None}\n",
    "    gwb1 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L1], ytr)\n",
    "    gwb2 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L2], ytr)\n",
    "    gwb3 = GWBProbEstimator(**gwb_kwargs).fit(Xtr2[L3], ytr)\n",
    "    p1_va = gwb1.predict_proba(Xva2[L1]); p2_va = gwb2.predict_proba(Xva2[L2]); p3_va = gwb3.predict_proba(Xva2[L3])\n",
    "    p1_te = gwb1.predict_proba(Xte2[L1]); p2_te = gwb2.predict_proba(Xte2[L2]); p3_te = gwb3.predict_proba(Xte2[L3])\n",
    "    # === 验证集上 PSO 学阈值 ===\n",
    "    s3 = S3WDParams(\n",
    "        c1=V[\"S3_c1\"], c2=V[\"S3_c2\"], xi_min=V[\"S3_xi_min\"],\n",
    "        theta_pos=V[\"S3_theta_pos\"], theta_neg=V[\"S3_theta_neg\"],\n",
    "        penalty_large=V[\"S3_penalty_large\"]  # 若你的 S3WDParams 支持 gamma_last/gap，这里再加\n",
    "    )\n",
    "    pso = PSOParams(\n",
    "        particles=V[\"PSO_particles\"], iters=V[\"PSO_iters\"],\n",
    "        w_max=V[\"PSO_w_max\"], w_min=V[\"PSO_w_min\"],\n",
    "        c1=V[\"PSO_c1\"], c2=V[\"PSO_c2\"], seed=seed\n",
    "    )\n",
    "    (alphas, betas, gamma3), fit, detail = pso_learn_thresholds([p1_va, p2_va, p3_va], yva.values, s3, pso)\n",
    "\n",
    "    # === 测试集序贯三支决策 + 指标（MCC 传 y_true,y_pred；AUC 兜底）===\n",
    "    y_hat, flow = _seq_predict(p1_te, p2_te, p3_te, yte.values,\n",
    "                               float(alphas[0]), float(betas[0]),\n",
    "                               float(alphas[1]), float(betas[1]),\n",
    "                               float(gamma3))\n",
    "    mask = (y_hat >= 0)\n",
    "    yt, yp = yte[mask], y_hat[mask]\n",
    "    metrics = {\n",
    "        'F1':   f1_score(yt, yp),\n",
    "        'BAC':  balanced_accuracy_score(yt, yp),\n",
    "        'Prec': precision_score(yt, yp),\n",
    "        'Rec':  recall_score(yt, yp),\n",
    "        'MCC':  matthews_corrcoef(yt, yp),\n",
    "        'Kappa':cohen_kappa_score(yt, yp),\n",
    "        'AUC':  _safe_auc(yt, yp),\n",
    "    }\n",
    "    th = {'alpha1': float(alphas[0]), 'beta1': float(betas[0]),\n",
    "          'alpha2': float(alphas[1]), 'beta2': float(betas[1]), 'gamma3': float(gamma3)}\n",
    "    return metrics, flow, th, {'fit':float(fit), 'pen_bnd':detail.get('pen_bnd',0.0), 'pen_mono':detail.get('pen_mono',0.0)}\n",
    "\n",
    "# —— 跑 10 次 —— #\n",
    "rows = []\n",
    "base_seed = V.get(\"PSO_seed\", 42)\n",
    "for i in range(10):\n",
    "    m, flow, th, det = run_one_split(seed=base_seed + i)\n",
    "    rows.append({\n",
    "        **{k: (round(v,4) if isinstance(v, (int,float)) else v) for k,v in m.items()},\n",
    "        'L1_POS': flow['L1'][0], 'L1_BND': flow['L1'][1], 'L1_NEG': flow['L1'][2],\n",
    "        'L2_POS': flow['L2'][0], 'L2_BND': flow['L2'][1], 'L2_NEG': flow['L2'][2],\n",
    "        'L3_POS': flow['L3'][0], 'L3_NEG': flow['L3'][1],\n",
    "        **{k: round(v,4) for k,v in th.items()},\n",
    "        **{k: round(v,4) for k,v in det.items()}\n",
    "    })\n",
    "\n",
    "df_res = pd.DataFrame(rows)\n",
    "print(\"【10 次独立划分结果（前 5 行）】\")\n",
    "display(df_res.head())\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'mean': df_res.mean(numeric_only=True).round(4),\n",
    "    'std':  df_res.std(numeric_only=True).round(4)\n",
    "})\n",
    "print(\"【均值 ± 标准差】\")\n",
    "display(summary.loc[['F1','BAC','Prec','Rec','MCC','Kappa','AUC']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719df993",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary.to_excel('../targets/airline_gwb.xlsx')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
